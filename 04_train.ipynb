{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression\n",
      "Epoch 10, Train Loss: 0.5820, Val Loss: 0.6100\n",
      "Epoch 20, Train Loss: 0.5060, Val Loss: 0.5327\n",
      "Epoch 30, Train Loss: 0.4579, Val Loss: 0.4773\n",
      "Epoch 40, Train Loss: 0.4223, Val Loss: 0.4530\n",
      "Epoch 50, Train Loss: 0.3991, Val Loss: 0.4354\n",
      "Epoch 60, Train Loss: 0.3785, Val Loss: 0.4146\n",
      "Epoch 70, Train Loss: 0.3665, Val Loss: 0.4096\n",
      "\n",
      "Evaluating Logistic Regression\n",
      "Accuracy: 0.9142857142857143\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93        20\n",
      "         1.0       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.91        35\n",
      "   macro avg       0.93      0.90      0.91        35\n",
      "weighted avg       0.93      0.91      0.91        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 3 12]]\n",
      "\n",
      "Training MLP\n",
      "Epoch 10, Train Loss: 0.3853, Val Loss: 0.4438\n",
      "Epoch 20, Train Loss: 0.2806, Val Loss: 0.3605\n",
      "Epoch 30, Train Loss: 0.2507, Val Loss: 0.2957\n",
      "Epoch 40, Train Loss: 0.2228, Val Loss: 0.2693\n",
      "Epoch 50, Train Loss: 0.2110, Val Loss: 0.2585\n",
      "Epoch 60, Train Loss: 0.2198, Val Loss: 0.2981\n",
      "Epoch 70, Train Loss: 0.1723, Val Loss: 0.2406\n",
      "\n",
      "Evaluating MLP\n",
      "Accuracy: 0.9428571428571428\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        20\n",
      "         1.0       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.94        35\n",
      "   macro avg       0.95      0.93      0.94        35\n",
      "weighted avg       0.95      0.94      0.94        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 2 13]]\n",
      "\n",
      "Training LSTM\n",
      "Epoch 10, Train Loss: 0.4803, Val Loss: 0.5769\n",
      "Epoch 20, Train Loss: 0.4773, Val Loss: 0.6703\n",
      "Epoch 30, Train Loss: 0.2929, Val Loss: 0.5742\n",
      "Epoch 40, Train Loss: 0.2467, Val Loss: 0.4253\n",
      "Epoch 50, Train Loss: 0.1830, Val Loss: 0.3488\n",
      "Epoch 60, Train Loss: 0.1959, Val Loss: 0.5294\n",
      "Epoch 70, Train Loss: 0.1920, Val Loss: 0.3158\n",
      "\n",
      "Evaluating LSTM\n",
      "Accuracy: 0.8857142857142857\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90        20\n",
      "         1.0       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.89        35\n",
      "   macro avg       0.88      0.88      0.88        35\n",
      "weighted avg       0.89      0.89      0.89        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  2]\n",
      " [ 2 13]]\n",
      "\n",
      "Training Bidirectional LSTM\n",
      "Epoch 10, Train Loss: 0.4683, Val Loss: 0.6512\n",
      "Epoch 20, Train Loss: 0.6273, Val Loss: 0.6055\n",
      "Epoch 30, Train Loss: 0.4059, Val Loss: 0.5874\n",
      "Epoch 40, Train Loss: 0.3487, Val Loss: 0.4307\n",
      "Epoch 50, Train Loss: 0.2593, Val Loss: 0.4276\n",
      "Epoch 60, Train Loss: 0.2908, Val Loss: 0.3824\n",
      "Epoch 70, Train Loss: 0.2343, Val Loss: 0.3734\n",
      "\n",
      "Evaluating Bidirectional LSTM\n",
      "Accuracy: 0.9428571428571428\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        20\n",
      "         1.0       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.94        35\n",
      "   macro avg       0.95      0.93      0.94        35\n",
      "weighted avg       0.95      0.94      0.94        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 2 13]]\n",
      "\n",
      "Summary of Results:\n",
      "Logistic Regression: Accuracy = 0.9143, Training Time = 0.31 seconds\n",
      "MLP: Accuracy = 0.9429, Training Time = 0.52 seconds\n",
      "LSTM: Accuracy = 0.8857, Training Time = 5.31 seconds\n",
      "Bidirectional LSTM: Accuracy = 0.9429, Training Time = 10.50 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# Load data\n",
    "data_dir = 'sequences'\n",
    "data = torch.load(os.path.join(data_dir, 'data_balanced.pt'))\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a directory to save the best models\n",
    "models_dir = 'models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "# Define training loop\n",
    "def train(model, train_loader, val_loader, epochs=10, patience=5, model_class=None, description=None):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.unsqueeze(1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = validate(model, val_loader, criterion)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}, Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        if description:\n",
    "            model_path = os.path.join(models_dir, f'{description}_{name.replace(\" \", \"_\").lower()}.pth')\n",
    "        else:\n",
    "            model_path = os.path.join(models_dir, f'{name.replace(\" \", \"_\").lower()}.pth')\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model, model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == patience:\n",
    "            print('Early stopping!')\n",
    "            model = torch.load(model_path)  # Load the entire model\n",
    "            return\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.unsqueeze(1).float())\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(all_labels, all_preds))\n",
    "    return accuracy\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class FlattenModel(BaseModel):\n",
    "    def forward(self, x):\n",
    "        return self._forward(x.view(x.size(0), -1))\n",
    "\n",
    "    def _forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class LogisticRegression(FlattenModel):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def _forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class MLP(FlattenModel):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def _forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class LSTMModel(BaseModel):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return self.fc(h_n[-1])\n",
    "\n",
    "class BidirectionalLSTMModel(BaseModel):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(BidirectionalLSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)  # *2 because it's bidirectional\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        x = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# Update the models dictionary\n",
    "input_dim = 64 * 8  # Assuming your input shape is (batch_size, 64, 8)\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(input_dim),\n",
    "    'MLP': MLP(input_dim),\n",
    "    'LSTM': LSTMModel(input_size=8, hidden_size=128, num_layers=1),\n",
    "    'Bidirectional LSTM': BidirectionalLSTMModel(input_size=8, hidden_size=128, num_layers=1),\n",
    "}\n",
    "\n",
    "\n",
    "train_description = \"v3\"\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}\")\n",
    "    start_time = time.time()\n",
    "    train(model, train_loader, val_loader, epochs=70, patience=5, model_class=type(model), description=train_description)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nEvaluating {name}\")\n",
    "    accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    results[name] = {'accuracy': accuracy, 'train_time': train_time}\n",
    "\n",
    "# Print summary of results\n",
    "print(\"\\nSummary of Results:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}: Accuracy = {result['accuracy']:.4f}, Training Time = {result['train_time']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_balanced_seq_len_128_overlap_16.pt', 'data_balanced_seq_len_128_overlap_32.pt', 'data_balanced_seq_len_128_overlap_64.pt', 'data_balanced_seq_len_32_overlap_16.pt', 'data_balanced_seq_len_32_overlap_32.pt', 'data_balanced_seq_len_32_overlap_64.pt', 'data_balanced_seq_len_64_overlap_16.pt', 'data_balanced_seq_len_64_overlap_32.pt', 'data_balanced_seq_len_64_overlap_64.pt']\n",
      "\n",
      "Training Logistic Regression on data_balanced_seq_len_128_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.5092, Val Loss: 0.5571\n",
      "Epoch 20, Train Loss: 0.4164, Val Loss: 0.4708\n",
      "Epoch 30, Train Loss: 0.3719, Val Loss: 0.4393\n",
      "Epoch 40, Train Loss: 0.3395, Val Loss: 0.4209\n",
      "Epoch 50, Train Loss: 0.3198, Val Loss: 0.4082\n",
      "Epoch 60, Train Loss: 0.2958, Val Loss: 0.3990\n",
      "Epoch 70, Train Loss: 0.2812, Val Loss: 0.3980\n",
      "\n",
      "Evaluating Logistic Regression on data_balanced_seq_len_128_overlap_16.pt\n",
      "Accuracy: 0.82\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.83      0.77        18\n",
      "         1.0       0.90      0.81      0.85        32\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.81      0.82      0.81        50\n",
      "weighted avg       0.83      0.82      0.82        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 6 26]]\n",
      "\n",
      "Training MLP on data_balanced_seq_len_128_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.4025, Val Loss: 0.4374\n",
      "Epoch 20, Train Loss: 0.2631, Val Loss: 0.3948\n",
      "Epoch 30, Train Loss: 0.2176, Val Loss: 0.3791\n",
      "Epoch 40, Train Loss: 0.1885, Val Loss: 0.3776\n",
      "Epoch 50, Train Loss: 0.1876, Val Loss: 0.3739\n",
      "Epoch 60, Train Loss: 0.1698, Val Loss: 0.5168\n",
      "Epoch 70, Train Loss: 0.1392, Val Loss: 0.3730\n",
      "\n",
      "Evaluating MLP on data_balanced_seq_len_128_overlap_16.pt\n",
      "Accuracy: 0.96\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        18\n",
      "         1.0       0.97      0.97      0.97        32\n",
      "\n",
      "    accuracy                           0.96        50\n",
      "   macro avg       0.96      0.96      0.96        50\n",
      "weighted avg       0.96      0.96      0.96        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  1]\n",
      " [ 1 31]]\n",
      "\n",
      "Training LSTM on data_balanced_seq_len_128_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.6324, Val Loss: 0.6627\n",
      "Epoch 20, Train Loss: 0.6156, Val Loss: 0.6582\n",
      "Epoch 30, Train Loss: 0.5795, Val Loss: 0.6285\n",
      "Epoch 40, Train Loss: 0.5263, Val Loss: 0.5169\n",
      "Epoch 50, Train Loss: 0.5696, Val Loss: 0.6012\n",
      "Epoch 60, Train Loss: 0.5705, Val Loss: 0.5694\n",
      "Epoch 70, Train Loss: 0.6113, Val Loss: 0.6129\n",
      "\n",
      "Evaluating LSTM on data_balanced_seq_len_128_overlap_16.pt\n",
      "Accuracy: 0.6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.56      0.50        18\n",
      "         1.0       0.71      0.62      0.67        32\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.58      0.59      0.58        50\n",
      "weighted avg       0.62      0.60      0.61        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  8]\n",
      " [12 20]]\n",
      "\n",
      "Training Bidirectional LSTM on data_balanced_seq_len_128_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.6571, Val Loss: 0.6645\n",
      "Epoch 20, Train Loss: 0.5838, Val Loss: 0.6026\n",
      "Epoch 30, Train Loss: 0.6161, Val Loss: 0.6608\n",
      "Epoch 40, Train Loss: 0.5854, Val Loss: 0.6105\n",
      "Epoch 50, Train Loss: 0.5811, Val Loss: 0.6566\n",
      "Epoch 60, Train Loss: 0.5610, Val Loss: 0.5947\n",
      "Epoch 70, Train Loss: 0.5383, Val Loss: 0.5763\n",
      "\n",
      "Evaluating Bidirectional LSTM on data_balanced_seq_len_128_overlap_16.pt\n",
      "Accuracy: 0.62\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.17      0.24        18\n",
      "         1.0       0.65      0.88      0.75        32\n",
      "\n",
      "    accuracy                           0.62        50\n",
      "   macro avg       0.54      0.52      0.49        50\n",
      "weighted avg       0.57      0.62      0.56        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3 15]\n",
      " [ 4 28]]\n",
      "\n",
      "Training Logistic Regression on data_balanced_seq_len_128_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.6019, Val Loss: 0.6474\n",
      "Epoch 20, Train Loss: 0.5242, Val Loss: 0.5580\n",
      "Epoch 30, Train Loss: 0.4733, Val Loss: 0.5218\n",
      "Epoch 40, Train Loss: 0.4329, Val Loss: 0.4875\n",
      "Epoch 50, Train Loss: 0.4029, Val Loss: 0.4431\n",
      "Epoch 60, Train Loss: 0.3791, Val Loss: 0.4392\n",
      "Epoch 70, Train Loss: 0.3664, Val Loss: 0.4583\n",
      "\n",
      "Evaluating Logistic Regression on data_balanced_seq_len_128_overlap_32.pt\n",
      "Accuracy: 0.8285714285714286\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.90      0.86        20\n",
      "         1.0       0.85      0.73      0.79        15\n",
      "\n",
      "    accuracy                           0.83        35\n",
      "   macro avg       0.83      0.82      0.82        35\n",
      "weighted avg       0.83      0.83      0.83        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  2]\n",
      " [ 4 11]]\n",
      "\n",
      "Training MLP on data_balanced_seq_len_128_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.5045, Val Loss: 0.5248\n",
      "Epoch 20, Train Loss: 0.3588, Val Loss: 0.4672\n",
      "Epoch 30, Train Loss: 0.3408, Val Loss: 0.4909\n",
      "Epoch 40, Train Loss: 0.2431, Val Loss: 0.3777\n",
      "Epoch 50, Train Loss: 0.1919, Val Loss: 0.4486\n",
      "Epoch 60, Train Loss: 0.1829, Val Loss: 0.3786\n",
      "Epoch 70, Train Loss: 0.1699, Val Loss: 0.4788\n",
      "\n",
      "Evaluating MLP on data_balanced_seq_len_128_overlap_32.pt\n",
      "Accuracy: 0.8571428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.90      0.88        20\n",
      "         1.0       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.86      0.85      0.85        35\n",
      "weighted avg       0.86      0.86      0.86        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  2]\n",
      " [ 3 12]]\n",
      "\n",
      "Training LSTM on data_balanced_seq_len_128_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.6783, Val Loss: 0.6757\n",
      "Epoch 20, Train Loss: 0.6537, Val Loss: 0.6976\n",
      "Epoch 30, Train Loss: 0.6998, Val Loss: 0.6189\n",
      "Epoch 40, Train Loss: 0.5782, Val Loss: 0.6133\n",
      "Epoch 50, Train Loss: 0.6062, Val Loss: 0.5474\n",
      "Epoch 60, Train Loss: 0.6151, Val Loss: 0.6287\n",
      "Epoch 70, Train Loss: 0.5595, Val Loss: 0.5987\n",
      "\n",
      "Evaluating LSTM on data_balanced_seq_len_128_overlap_32.pt\n",
      "Accuracy: 0.7142857142857143\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80        20\n",
      "         1.0       1.00      0.33      0.50        15\n",
      "\n",
      "    accuracy                           0.71        35\n",
      "   macro avg       0.83      0.67      0.65        35\n",
      "weighted avg       0.81      0.71      0.67        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [10  5]]\n",
      "\n",
      "Training Bidirectional LSTM on data_balanced_seq_len_128_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.6830, Val Loss: 0.6734\n",
      "Epoch 20, Train Loss: 0.6724, Val Loss: 0.6712\n",
      "Epoch 30, Train Loss: 0.6783, Val Loss: 0.7523\n",
      "Epoch 40, Train Loss: 0.6717, Val Loss: 0.5582\n",
      "Epoch 50, Train Loss: 0.6106, Val Loss: 0.5367\n",
      "Epoch 60, Train Loss: 0.5684, Val Loss: 0.5200\n",
      "Epoch 70, Train Loss: 0.5174, Val Loss: 0.4853\n",
      "\n",
      "Evaluating Bidirectional LSTM on data_balanced_seq_len_128_overlap_32.pt\n",
      "Accuracy: 0.7714285714285715\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.83        20\n",
      "         1.0       0.89      0.53      0.67        15\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.81      0.74      0.75        35\n",
      "weighted avg       0.80      0.77      0.76        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  1]\n",
      " [ 7  8]]\n",
      "\n",
      "Training Logistic Regression on data_balanced_seq_len_128_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.5730, Val Loss: 0.4818\n",
      "Epoch 20, Train Loss: 0.5242, Val Loss: 0.4766\n",
      "Epoch 30, Train Loss: 0.4783, Val Loss: 0.4425\n",
      "Epoch 40, Train Loss: 0.4431, Val Loss: 0.4174\n",
      "Epoch 50, Train Loss: 0.4217, Val Loss: 0.4130\n",
      "Epoch 60, Train Loss: 0.3881, Val Loss: 0.3853\n",
      "Epoch 70, Train Loss: 0.3666, Val Loss: 0.3658\n",
      "\n",
      "Evaluating Logistic Regression on data_balanced_seq_len_128_overlap_64.pt\n",
      "Accuracy: 0.9615384615384616\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97        17\n",
      "         1.0       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.97      0.94      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  0]\n",
      " [ 1  8]]\n",
      "\n",
      "Training MLP on data_balanced_seq_len_128_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.5512, Val Loss: 0.4692\n",
      "Epoch 20, Train Loss: 0.4458, Val Loss: 0.3769\n",
      "Epoch 30, Train Loss: 0.3353, Val Loss: 0.3197\n",
      "Epoch 40, Train Loss: 0.2386, Val Loss: 0.2740\n",
      "Epoch 50, Train Loss: 0.1731, Val Loss: 0.2282\n",
      "Epoch 60, Train Loss: 0.1353, Val Loss: 0.1796\n",
      "Epoch 70, Train Loss: 0.1075, Val Loss: 0.1619\n",
      "\n",
      "Evaluating MLP on data_balanced_seq_len_128_overlap_64.pt\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        17\n",
      "         1.0       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  0]\n",
      " [ 0  9]]\n",
      "\n",
      "Training LSTM on data_balanced_seq_len_128_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.6124, Val Loss: 0.5119\n",
      "Epoch 20, Train Loss: 0.5755, Val Loss: 0.4883\n",
      "Epoch 30, Train Loss: 0.5894, Val Loss: 0.4823\n",
      "Epoch 40, Train Loss: 0.6198, Val Loss: 0.5958\n",
      "Epoch 50, Train Loss: 0.5286, Val Loss: 0.4722\n",
      "Epoch 60, Train Loss: 0.4875, Val Loss: 0.5208\n",
      "Epoch 70, Train Loss: 0.5520, Val Loss: 0.4727\n",
      "\n",
      "Evaluating LSTM on data_balanced_seq_len_128_overlap_64.pt\n",
      "Accuracy: 0.6538461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      1.00      0.79        17\n",
      "         1.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.33      0.50      0.40        26\n",
      "weighted avg       0.43      0.65      0.52        26\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  0]\n",
      " [ 9  0]]\n",
      "\n",
      "Training Bidirectional LSTM on data_balanced_seq_len_128_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.6231, Val Loss: 0.5511\n",
      "Epoch 20, Train Loss: 0.6286, Val Loss: 0.5659\n",
      "Epoch 30, Train Loss: 0.5744, Val Loss: 0.4826\n",
      "Epoch 40, Train Loss: 0.5051, Val Loss: 0.4959\n",
      "Epoch 50, Train Loss: 0.6521, Val Loss: 0.6194\n",
      "Epoch 60, Train Loss: 0.6158, Val Loss: 0.5201\n",
      "Epoch 70, Train Loss: 0.6054, Val Loss: 0.5495\n",
      "\n",
      "Evaluating Bidirectional LSTM on data_balanced_seq_len_128_overlap_64.pt\n",
      "Accuracy: 0.6538461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      1.00      0.79        17\n",
      "         1.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.33      0.50      0.40        26\n",
      "weighted avg       0.43      0.65      0.52        26\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  0]\n",
      " [ 9  0]]\n",
      "\n",
      "Training Logistic Regression on data_balanced_seq_len_32_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.6133, Val Loss: 0.6589\n",
      "Epoch 20, Train Loss: 0.5696, Val Loss: 0.6269\n",
      "Epoch 30, Train Loss: 0.5377, Val Loss: 0.6017\n",
      "Epoch 40, Train Loss: 0.5104, Val Loss: 0.5847\n",
      "Epoch 50, Train Loss: 0.4899, Val Loss: 0.5688\n",
      "Epoch 60, Train Loss: 0.4711, Val Loss: 0.5556\n",
      "Epoch 70, Train Loss: 0.4571, Val Loss: 0.5454\n",
      "\n",
      "Evaluating Logistic Regression on data_balanced_seq_len_32_overlap_16.pt\n",
      "Accuracy: 0.74\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.56      0.61        18\n",
      "         1.0       0.77      0.84      0.81        32\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.72      0.70      0.71        50\n",
      "weighted avg       0.73      0.74      0.73        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  8]\n",
      " [ 5 27]]\n",
      "\n",
      "Training MLP on data_balanced_seq_len_32_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.5254, Val Loss: 0.5613\n",
      "Epoch 20, Train Loss: 0.4524, Val Loss: 0.4981\n",
      "Epoch 30, Train Loss: 0.3593, Val Loss: 0.4586\n",
      "Epoch 40, Train Loss: 0.3275, Val Loss: 0.4424\n",
      "Epoch 50, Train Loss: 0.3559, Val Loss: 0.4302\n",
      "Epoch 60, Train Loss: 0.3020, Val Loss: 0.4263\n",
      "Epoch 70, Train Loss: 0.2936, Val Loss: 0.4440\n",
      "\n",
      "Evaluating MLP on data_balanced_seq_len_32_overlap_16.pt\n",
      "Accuracy: 0.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.89      0.80        18\n",
      "         1.0       0.93      0.81      0.87        32\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.83      0.85      0.83        50\n",
      "weighted avg       0.86      0.84      0.84        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16  2]\n",
      " [ 6 26]]\n",
      "\n",
      "Training LSTM on data_balanced_seq_len_32_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.4864, Val Loss: 0.6265\n",
      "Epoch 20, Train Loss: 0.4521, Val Loss: 0.7160\n",
      "Epoch 30, Train Loss: 0.4224, Val Loss: 0.5400\n",
      "Epoch 40, Train Loss: 0.3894, Val Loss: 0.5140\n",
      "Epoch 50, Train Loss: 0.3920, Val Loss: 0.5046\n",
      "Epoch 60, Train Loss: 0.3600, Val Loss: 0.5015\n",
      "Epoch 70, Train Loss: 0.3687, Val Loss: 0.5726\n",
      "\n",
      "Evaluating LSTM on data_balanced_seq_len_32_overlap_16.pt\n",
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.61      0.65        18\n",
      "         1.0       0.79      0.84      0.82        32\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.74      0.73      0.73        50\n",
      "weighted avg       0.76      0.76      0.76        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11  7]\n",
      " [ 5 27]]\n",
      "\n",
      "Training Bidirectional LSTM on data_balanced_seq_len_32_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.5690, Val Loss: 0.5999\n",
      "Epoch 20, Train Loss: 0.4276, Val Loss: 0.5745\n",
      "Epoch 30, Train Loss: 0.3944, Val Loss: 0.5810\n",
      "Epoch 40, Train Loss: 0.4147, Val Loss: 0.5421\n",
      "Epoch 50, Train Loss: 0.3722, Val Loss: 0.4754\n",
      "Epoch 60, Train Loss: 0.3445, Val Loss: 0.5169\n",
      "Epoch 70, Train Loss: 0.3515, Val Loss: 0.4718\n",
      "\n",
      "Evaluating Bidirectional LSTM on data_balanced_seq_len_32_overlap_16.pt\n",
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.61      0.65        18\n",
      "         1.0       0.79      0.84      0.82        32\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.74      0.73      0.73        50\n",
      "weighted avg       0.76      0.76      0.76        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11  7]\n",
      " [ 5 27]]\n",
      "\n",
      "Training Logistic Regression on data_balanced_seq_len_32_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.6721, Val Loss: 0.6634\n",
      "Epoch 20, Train Loss: 0.6605, Val Loss: 0.6537\n",
      "Epoch 30, Train Loss: 0.6520, Val Loss: 0.6441\n",
      "Epoch 40, Train Loss: 0.6459, Val Loss: 0.6344\n",
      "Epoch 50, Train Loss: 0.6254, Val Loss: 0.6266\n",
      "Epoch 60, Train Loss: 0.6263, Val Loss: 0.6180\n",
      "Epoch 70, Train Loss: 0.6165, Val Loss: 0.6138\n",
      "\n",
      "Evaluating Logistic Regression on data_balanced_seq_len_32_overlap_32.pt\n",
      "Accuracy: 0.7878787878787878\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.83      0.81        18\n",
      "         1.0       0.79      0.73      0.76        15\n",
      "\n",
      "    accuracy                           0.79        33\n",
      "   macro avg       0.79      0.78      0.78        33\n",
      "weighted avg       0.79      0.79      0.79        33\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 4 11]]\n",
      "\n",
      "Training MLP on data_balanced_seq_len_32_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.6409, Val Loss: 0.6282\n",
      "Epoch 20, Train Loss: 0.5991, Val Loss: 0.5818\n",
      "Epoch 30, Train Loss: 0.5947, Val Loss: 0.5626\n",
      "Epoch 40, Train Loss: 0.5258, Val Loss: 0.5378\n",
      "Epoch 50, Train Loss: 0.5428, Val Loss: 0.5222\n",
      "Epoch 60, Train Loss: 0.5458, Val Loss: 0.5136\n",
      "Epoch 70, Train Loss: 0.4970, Val Loss: 0.5008\n",
      "\n",
      "Evaluating MLP on data_balanced_seq_len_32_overlap_32.pt\n",
      "Accuracy: 0.8181818181818182\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.89      0.84        18\n",
      "         1.0       0.85      0.73      0.79        15\n",
      "\n",
      "    accuracy                           0.82        33\n",
      "   macro avg       0.82      0.81      0.81        33\n",
      "weighted avg       0.82      0.82      0.82        33\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16  2]\n",
      " [ 4 11]]\n",
      "\n",
      "Training LSTM on data_balanced_seq_len_32_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.6873, Val Loss: 0.6846\n",
      "Epoch 20, Train Loss: 0.6778, Val Loss: 0.6718\n",
      "Epoch 30, Train Loss: 0.6074, Val Loss: 0.5578\n",
      "Epoch 40, Train Loss: 0.7645, Val Loss: 0.8331\n",
      "Epoch 50, Train Loss: 0.6118, Val Loss: 0.6087\n",
      "Epoch 60, Train Loss: 0.5787, Val Loss: 0.5817\n",
      "Epoch 70, Train Loss: 0.5422, Val Loss: 0.4882\n",
      "\n",
      "Evaluating LSTM on data_balanced_seq_len_32_overlap_32.pt\n",
      "Accuracy: 0.7272727272727273\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.83      0.77        18\n",
      "         1.0       0.75      0.60      0.67        15\n",
      "\n",
      "    accuracy                           0.73        33\n",
      "   macro avg       0.73      0.72      0.72        33\n",
      "weighted avg       0.73      0.73      0.72        33\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 6  9]]\n",
      "\n",
      "Training Bidirectional LSTM on data_balanced_seq_len_32_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.6714, Val Loss: 0.6168\n",
      "Epoch 20, Train Loss: 0.6124, Val Loss: 0.5315\n",
      "Epoch 30, Train Loss: 0.5536, Val Loss: 0.5321\n",
      "Epoch 40, Train Loss: 0.5187, Val Loss: 0.5127\n",
      "Epoch 50, Train Loss: 0.5101, Val Loss: 0.5243\n",
      "Epoch 60, Train Loss: 0.4743, Val Loss: 0.5648\n",
      "Epoch 70, Train Loss: 0.4765, Val Loss: 0.5420\n",
      "\n",
      "Evaluating Bidirectional LSTM on data_balanced_seq_len_32_overlap_32.pt\n",
      "Accuracy: 0.8484848484848485\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.94      0.87        18\n",
      "         1.0       0.92      0.73      0.81        15\n",
      "\n",
      "    accuracy                           0.85        33\n",
      "   macro avg       0.86      0.84      0.84        33\n",
      "weighted avg       0.86      0.85      0.85        33\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  1]\n",
      " [ 4 11]]\n",
      "\n",
      "Training Logistic Regression on data_balanced_seq_len_32_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.5791, Val Loss: 0.4363\n",
      "Epoch 20, Train Loss: 0.5664, Val Loss: 0.4338\n",
      "Epoch 30, Train Loss: 0.5538, Val Loss: 0.4228\n",
      "Epoch 40, Train Loss: 0.5426, Val Loss: 0.4165\n",
      "Epoch 50, Train Loss: 0.5330, Val Loss: 0.4152\n",
      "Epoch 60, Train Loss: 0.5248, Val Loss: 0.4074\n",
      "Epoch 70, Train Loss: 0.5140, Val Loss: 0.4046\n",
      "\n",
      "Evaluating Logistic Regression on data_balanced_seq_len_32_overlap_64.pt\n",
      "Accuracy: 0.8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      1.00      0.88        18\n",
      "         1.0       1.00      0.29      0.44         7\n",
      "\n",
      "    accuracy                           0.80        25\n",
      "   macro avg       0.89      0.64      0.66        25\n",
      "weighted avg       0.84      0.80      0.76        25\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  0]\n",
      " [ 5  2]]\n",
      "\n",
      "Training MLP on data_balanced_seq_len_32_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.5765, Val Loss: 0.4082\n",
      "Epoch 20, Train Loss: 0.5301, Val Loss: 0.3976\n",
      "Epoch 30, Train Loss: 0.4891, Val Loss: 0.3830\n",
      "Epoch 40, Train Loss: 0.4547, Val Loss: 0.3622\n",
      "Epoch 50, Train Loss: 0.4234, Val Loss: 0.3673\n",
      "Epoch 60, Train Loss: 0.4010, Val Loss: 0.3512\n",
      "Epoch 70, Train Loss: 0.3805, Val Loss: 0.3419\n",
      "\n",
      "Evaluating MLP on data_balanced_seq_len_32_overlap_64.pt\n",
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83        18\n",
      "         1.0       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.76        25\n",
      "   macro avg       0.70      0.70      0.70        25\n",
      "weighted avg       0.76      0.76      0.76        25\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 3  4]]\n",
      "\n",
      "Training LSTM on data_balanced_seq_len_32_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.5836, Val Loss: 0.5044\n",
      "Epoch 20, Train Loss: 0.5218, Val Loss: 0.3129\n",
      "Epoch 30, Train Loss: 0.4967, Val Loss: 0.2920\n",
      "Epoch 40, Train Loss: 0.5654, Val Loss: 0.4540\n",
      "Epoch 50, Train Loss: 0.4885, Val Loss: 0.3146\n",
      "Epoch 60, Train Loss: 0.4583, Val Loss: 0.3146\n",
      "Epoch 70, Train Loss: 0.4543, Val Loss: 0.2943\n",
      "\n",
      "Evaluating LSTM on data_balanced_seq_len_32_overlap_64.pt\n",
      "Accuracy: 0.68\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.83      0.79        18\n",
      "         1.0       0.40      0.29      0.33         7\n",
      "\n",
      "    accuracy                           0.68        25\n",
      "   macro avg       0.57      0.56      0.56        25\n",
      "weighted avg       0.65      0.68      0.66        25\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 5  2]]\n",
      "\n",
      "Training Bidirectional LSTM on data_balanced_seq_len_32_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.6042, Val Loss: 0.4540\n",
      "Epoch 20, Train Loss: 0.4771, Val Loss: 0.3544\n",
      "Epoch 30, Train Loss: 0.4510, Val Loss: 0.2999\n",
      "Epoch 40, Train Loss: 0.4095, Val Loss: 0.2926\n",
      "Epoch 50, Train Loss: 0.3817, Val Loss: 0.3027\n",
      "Epoch 60, Train Loss: 0.4276, Val Loss: 0.3081\n",
      "Epoch 70, Train Loss: 0.3597, Val Loss: 0.2544\n",
      "\n",
      "Evaluating Bidirectional LSTM on data_balanced_seq_len_32_overlap_64.pt\n",
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83        18\n",
      "         1.0       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.76        25\n",
      "   macro avg       0.70      0.70      0.70        25\n",
      "weighted avg       0.76      0.76      0.76        25\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 3  4]]\n",
      "\n",
      "Training Logistic Regression on data_balanced_seq_len_64_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.5490, Val Loss: 0.5861\n",
      "Epoch 20, Train Loss: 0.4679, Val Loss: 0.5179\n",
      "Epoch 30, Train Loss: 0.4184, Val Loss: 0.4790\n",
      "Epoch 40, Train Loss: 0.3862, Val Loss: 0.4551\n",
      "Epoch 50, Train Loss: 0.3725, Val Loss: 0.4419\n",
      "Epoch 60, Train Loss: 0.3498, Val Loss: 0.4291\n",
      "Epoch 70, Train Loss: 0.3375, Val Loss: 0.4204\n",
      "\n",
      "Evaluating Logistic Regression on data_balanced_seq_len_64_overlap_16.pt\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.78      0.80        18\n",
      "         1.0       0.88      0.91      0.89        32\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.85      0.84      0.85        50\n",
      "weighted avg       0.86      0.86      0.86        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14  4]\n",
      " [ 3 29]]\n",
      "\n",
      "Training MLP on data_balanced_seq_len_64_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.4544, Val Loss: 0.5078\n",
      "Epoch 20, Train Loss: 0.4098, Val Loss: 0.4641\n",
      "Epoch 30, Train Loss: 0.3834, Val Loss: 0.4392\n",
      "Epoch 40, Train Loss: 0.3871, Val Loss: 0.4283\n",
      "Epoch 50, Train Loss: 0.3604, Val Loss: 0.4089\n",
      "Epoch 60, Train Loss: 0.3377, Val Loss: 0.3961\n",
      "Epoch 70, Train Loss: 0.3464, Val Loss: 0.3956\n",
      "\n",
      "Evaluating MLP on data_balanced_seq_len_64_overlap_16.pt\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.72      0.81        18\n",
      "         1.0       0.86      0.97      0.91        32\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.89      0.85      0.86        50\n",
      "weighted avg       0.89      0.88      0.88        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13  5]\n",
      " [ 1 31]]\n",
      "\n",
      "Training LSTM on data_balanced_seq_len_64_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.6156, Val Loss: 0.6569\n",
      "Epoch 20, Train Loss: 0.7563, Val Loss: 0.8630\n",
      "Epoch 30, Train Loss: 0.4081, Val Loss: 0.4110\n",
      "Epoch 40, Train Loss: 0.6379, Val Loss: 0.6848\n",
      "Epoch 50, Train Loss: 0.2819, Val Loss: 0.4404\n",
      "Epoch 60, Train Loss: 0.7872, Val Loss: 0.8623\n",
      "Epoch 70, Train Loss: 0.2928, Val Loss: 0.4750\n",
      "\n",
      "Evaluating LSTM on data_balanced_seq_len_64_overlap_16.pt\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.83      0.81        18\n",
      "         1.0       0.90      0.88      0.89        32\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.85      0.85      0.85        50\n",
      "weighted avg       0.86      0.86      0.86        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 4 28]]\n",
      "\n",
      "Training Bidirectional LSTM on data_balanced_seq_len_64_overlap_16.pt\n",
      "Epoch 10, Train Loss: 0.5843, Val Loss: 0.6237\n",
      "Epoch 20, Train Loss: 0.5910, Val Loss: 0.6415\n",
      "Epoch 30, Train Loss: 0.4980, Val Loss: 0.9110\n",
      "Epoch 40, Train Loss: 0.3434, Val Loss: 0.3979\n",
      "Epoch 50, Train Loss: 0.3313, Val Loss: 0.4251\n",
      "Epoch 60, Train Loss: 0.2645, Val Loss: 0.4199\n",
      "Epoch 70, Train Loss: 0.2590, Val Loss: 0.4568\n",
      "\n",
      "Evaluating Bidirectional LSTM on data_balanced_seq_len_64_overlap_16.pt\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.83      0.81        18\n",
      "         1.0       0.90      0.88      0.89        32\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.85      0.85      0.85        50\n",
      "weighted avg       0.86      0.86      0.86        50\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 4 28]]\n",
      "\n",
      "Training Logistic Regression on data_balanced_seq_len_64_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.5712, Val Loss: 0.6030\n",
      "Epoch 20, Train Loss: 0.4990, Val Loss: 0.5325\n",
      "Epoch 30, Train Loss: 0.4482, Val Loss: 0.4748\n",
      "Epoch 40, Train Loss: 0.4193, Val Loss: 0.4573\n",
      "Epoch 50, Train Loss: 0.3933, Val Loss: 0.4249\n",
      "Epoch 60, Train Loss: 0.3757, Val Loss: 0.4106\n",
      "Epoch 70, Train Loss: 0.3640, Val Loss: 0.4046\n",
      "\n",
      "Evaluating Logistic Regression on data_balanced_seq_len_64_overlap_32.pt\n",
      "Accuracy: 0.9142857142857143\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93        20\n",
      "         1.0       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.91        35\n",
      "   macro avg       0.93      0.90      0.91        35\n",
      "weighted avg       0.93      0.91      0.91        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 3 12]]\n",
      "\n",
      "Training MLP on data_balanced_seq_len_64_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.5203, Val Loss: 0.5366\n",
      "Epoch 20, Train Loss: 0.3781, Val Loss: 0.4136\n",
      "Epoch 30, Train Loss: 0.3080, Val Loss: 0.3700\n",
      "Epoch 40, Train Loss: 0.2829, Val Loss: 0.3195\n",
      "Epoch 50, Train Loss: 0.2720, Val Loss: 0.3461\n",
      "Epoch 60, Train Loss: 0.2605, Val Loss: 0.3323\n",
      "Epoch 70, Train Loss: 0.2281, Val Loss: 0.2990\n",
      "\n",
      "Evaluating MLP on data_balanced_seq_len_64_overlap_32.pt\n",
      "Accuracy: 0.9428571428571428\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        20\n",
      "         1.0       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.94        35\n",
      "   macro avg       0.95      0.93      0.94        35\n",
      "weighted avg       0.95      0.94      0.94        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 2 13]]\n",
      "\n",
      "Training LSTM on data_balanced_seq_len_64_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.6391, Val Loss: 0.7372\n",
      "Epoch 20, Train Loss: 0.5586, Val Loss: 0.5931\n",
      "Epoch 30, Train Loss: 0.2853, Val Loss: 0.4447\n",
      "Epoch 40, Train Loss: 0.2333, Val Loss: 0.4522\n",
      "Epoch 50, Train Loss: 0.2212, Val Loss: 0.5205\n",
      "Epoch 60, Train Loss: 0.2507, Val Loss: 0.5359\n",
      "Epoch 70, Train Loss: 0.2444, Val Loss: 0.4119\n",
      "\n",
      "Evaluating LSTM on data_balanced_seq_len_64_overlap_32.pt\n",
      "Accuracy: 0.9428571428571428\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        20\n",
      "         1.0       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.94        35\n",
      "   macro avg       0.95      0.93      0.94        35\n",
      "weighted avg       0.95      0.94      0.94        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 2 13]]\n",
      "\n",
      "Training Bidirectional LSTM on data_balanced_seq_len_64_overlap_32.pt\n",
      "Epoch 10, Train Loss: 0.7318, Val Loss: 0.6606\n",
      "Epoch 20, Train Loss: 0.4470, Val Loss: 0.4989\n",
      "Epoch 30, Train Loss: 0.2465, Val Loss: 0.3838\n",
      "Epoch 40, Train Loss: 0.4991, Val Loss: 0.5867\n",
      "Epoch 50, Train Loss: 0.3737, Val Loss: 0.9690\n",
      "Epoch 60, Train Loss: 0.2670, Val Loss: 0.4255\n",
      "Epoch 70, Train Loss: 0.2699, Val Loss: 0.4195\n",
      "\n",
      "Evaluating Bidirectional LSTM on data_balanced_seq_len_64_overlap_32.pt\n",
      "Accuracy: 0.8857142857142857\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91        20\n",
      "         1.0       1.00      0.73      0.85        15\n",
      "\n",
      "    accuracy                           0.89        35\n",
      "   macro avg       0.92      0.87      0.88        35\n",
      "weighted avg       0.90      0.89      0.88        35\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 4 11]]\n",
      "\n",
      "Training Logistic Regression on data_balanced_seq_len_64_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.6303, Val Loss: 0.5982\n",
      "Epoch 20, Train Loss: 0.5581, Val Loss: 0.5540\n",
      "Epoch 30, Train Loss: 0.5377, Val Loss: 0.5245\n",
      "Epoch 40, Train Loss: 0.4769, Val Loss: 0.4897\n",
      "Epoch 50, Train Loss: 0.4913, Val Loss: 0.4665\n",
      "Epoch 60, Train Loss: 0.4351, Val Loss: 0.4440\n",
      "Epoch 70, Train Loss: 0.4161, Val Loss: 0.4246\n",
      "\n",
      "Evaluating Logistic Regression on data_balanced_seq_len_64_overlap_64.pt\n",
      "Accuracy: 0.8888888888888888\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93        20\n",
      "         1.0       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.93      0.79      0.83        27\n",
      "weighted avg       0.90      0.89      0.88        27\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 3  4]]\n",
      "\n",
      "Training MLP on data_balanced_seq_len_64_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.6015, Val Loss: 0.5817\n",
      "Epoch 20, Train Loss: 0.4645, Val Loss: 0.4854\n",
      "Epoch 30, Train Loss: 0.4183, Val Loss: 0.3818\n",
      "Epoch 40, Train Loss: 0.3148, Val Loss: 0.3172\n",
      "Epoch 50, Train Loss: 0.3956, Val Loss: 0.2872\n",
      "Epoch 60, Train Loss: 0.2965, Val Loss: 0.2722\n",
      "Epoch 70, Train Loss: 0.2223, Val Loss: 0.2644\n",
      "\n",
      "Evaluating MLP on data_balanced_seq_len_64_overlap_64.pt\n",
      "Accuracy: 0.8518518518518519\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.95      0.90        20\n",
      "         1.0       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.85        27\n",
      "   macro avg       0.83      0.76      0.79        27\n",
      "weighted avg       0.85      0.85      0.84        27\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  1]\n",
      " [ 3  4]]\n",
      "\n",
      "Training LSTM on data_balanced_seq_len_64_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.6765, Val Loss: 0.6501\n",
      "Epoch 20, Train Loss: 0.6513, Val Loss: 0.6578\n",
      "Epoch 30, Train Loss: 0.5914, Val Loss: 0.6841\n",
      "Epoch 40, Train Loss: 0.5725, Val Loss: 0.6156\n",
      "Epoch 50, Train Loss: 0.6606, Val Loss: 0.6656\n",
      "Epoch 60, Train Loss: 0.6044, Val Loss: 0.6334\n",
      "Epoch 70, Train Loss: 0.5403, Val Loss: 0.6049\n",
      "\n",
      "Evaluating LSTM on data_balanced_seq_len_64_overlap_64.pt\n",
      "Accuracy: 0.7407407407407407\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      1.00      0.85        20\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.74        27\n",
      "   macro avg       0.37      0.50      0.43        27\n",
      "weighted avg       0.55      0.74      0.63        27\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 7  0]]\n",
      "\n",
      "Training Bidirectional LSTM on data_balanced_seq_len_64_overlap_64.pt\n",
      "Epoch 10, Train Loss: 0.6558, Val Loss: 0.6406\n",
      "Epoch 20, Train Loss: 0.5052, Val Loss: 0.4986\n",
      "Epoch 30, Train Loss: 0.4961, Val Loss: 0.3998\n",
      "Epoch 40, Train Loss: 0.4858, Val Loss: 0.4304\n",
      "Epoch 50, Train Loss: 0.3176, Val Loss: 0.4038\n",
      "Epoch 60, Train Loss: 0.5516, Val Loss: 0.5299\n",
      "Epoch 70, Train Loss: 0.9602, Val Loss: 0.7763\n",
      "\n",
      "Evaluating Bidirectional LSTM on data_balanced_seq_len_64_overlap_64.pt\n",
      "Accuracy: 0.7407407407407407\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      1.00      0.85        20\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.74        27\n",
      "   macro avg       0.37      0.50      0.43        27\n",
      "weighted avg       0.55      0.74      0.63        27\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 7  0]]\n",
      "\n",
      "Summary of Results:\n",
      "Logistic Regression on data_balanced_seq_len_128_overlap_16.pt: Accuracy = 0.8200, Training Time = 0.42 seconds\n",
      "MLP on data_balanced_seq_len_128_overlap_16.pt: Accuracy = 0.9600, Training Time = 0.89 seconds\n",
      "LSTM on data_balanced_seq_len_128_overlap_16.pt: Accuracy = 0.6000, Training Time = 14.00 seconds\n",
      "Bidirectional LSTM on data_balanced_seq_len_128_overlap_16.pt: Accuracy = 0.6200, Training Time = 27.93 seconds\n",
      "Logistic Regression on data_balanced_seq_len_128_overlap_32.pt: Accuracy = 0.8286, Training Time = 0.32 seconds\n",
      "MLP on data_balanced_seq_len_128_overlap_32.pt: Accuracy = 0.8571, Training Time = 0.61 seconds\n",
      "LSTM on data_balanced_seq_len_128_overlap_32.pt: Accuracy = 0.7143, Training Time = 9.74 seconds\n",
      "Bidirectional LSTM on data_balanced_seq_len_128_overlap_32.pt: Accuracy = 0.7714, Training Time = 19.37 seconds\n",
      "Logistic Regression on data_balanced_seq_len_128_overlap_64.pt: Accuracy = 0.9615, Training Time = 0.24 seconds\n",
      "MLP on data_balanced_seq_len_128_overlap_64.pt: Accuracy = 1.0000, Training Time = 0.46 seconds\n",
      "LSTM on data_balanced_seq_len_128_overlap_64.pt: Accuracy = 0.6538, Training Time = 7.04 seconds\n",
      "Bidirectional LSTM on data_balanced_seq_len_128_overlap_64.pt: Accuracy = 0.6538, Training Time = 14.13 seconds\n",
      "Logistic Regression on data_balanced_seq_len_32_overlap_16.pt: Accuracy = 0.7400, Training Time = 0.44 seconds\n",
      "MLP on data_balanced_seq_len_32_overlap_16.pt: Accuracy = 0.8400, Training Time = 0.64 seconds\n",
      "LSTM on data_balanced_seq_len_32_overlap_16.pt: Accuracy = 0.7600, Training Time = 4.24 seconds\n",
      "Bidirectional LSTM on data_balanced_seq_len_32_overlap_16.pt: Accuracy = 0.7600, Training Time = 8.35 seconds\n",
      "Logistic Regression on data_balanced_seq_len_32_overlap_32.pt: Accuracy = 0.7879, Training Time = 0.29 seconds\n",
      "MLP on data_balanced_seq_len_32_overlap_32.pt: Accuracy = 0.8182, Training Time = 0.46 seconds\n",
      "LSTM on data_balanced_seq_len_32_overlap_32.pt: Accuracy = 0.7273, Training Time = 2.95 seconds\n",
      "Bidirectional LSTM on data_balanced_seq_len_32_overlap_32.pt: Accuracy = 0.8485, Training Time = 5.59 seconds\n",
      "Logistic Regression on data_balanced_seq_len_32_overlap_64.pt: Accuracy = 0.8000, Training Time = 0.23 seconds\n",
      "MLP on data_balanced_seq_len_32_overlap_64.pt: Accuracy = 0.7600, Training Time = 0.34 seconds\n",
      "LSTM on data_balanced_seq_len_32_overlap_64.pt: Accuracy = 0.6800, Training Time = 2.15 seconds\n",
      "Bidirectional LSTM on data_balanced_seq_len_32_overlap_64.pt: Accuracy = 0.7600, Training Time = 4.23 seconds\n",
      "Logistic Regression on data_balanced_seq_len_64_overlap_16.pt: Accuracy = 0.8600, Training Time = 0.42 seconds\n",
      "MLP on data_balanced_seq_len_64_overlap_16.pt: Accuracy = 0.8800, Training Time = 0.82 seconds\n",
      "LSTM on data_balanced_seq_len_64_overlap_16.pt: Accuracy = 0.8600, Training Time = 7.64 seconds\n",
      "Bidirectional LSTM on data_balanced_seq_len_64_overlap_16.pt: Accuracy = 0.8600, Training Time = 15.04 seconds\n",
      "Logistic Regression on data_balanced_seq_len_64_overlap_32.pt: Accuracy = 0.9143, Training Time = 0.31 seconds\n",
      "MLP on data_balanced_seq_len_64_overlap_32.pt: Accuracy = 0.9429, Training Time = 0.51 seconds\n",
      "LSTM on data_balanced_seq_len_64_overlap_32.pt: Accuracy = 0.9429, Training Time = 5.18 seconds\n",
      "Bidirectional LSTM on data_balanced_seq_len_64_overlap_32.pt: Accuracy = 0.8857, Training Time = 10.42 seconds\n",
      "Logistic Regression on data_balanced_seq_len_64_overlap_64.pt: Accuracy = 0.8889, Training Time = 0.27 seconds\n",
      "MLP on data_balanced_seq_len_64_overlap_64.pt: Accuracy = 0.8519, Training Time = 0.53 seconds\n",
      "LSTM on data_balanced_seq_len_64_overlap_64.pt: Accuracy = 0.7407, Training Time = 4.16 seconds\n",
      "Bidirectional LSTM on data_balanced_seq_len_64_overlap_64.pt: Accuracy = 0.7407, Training Time = 8.21 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get all data files in the sequences directory\n",
    "data_files = [file for file in os.listdir('sequences') if file.startswith('data_balanced_seq')]\n",
    "print(data_files)\n",
    "\n",
    "# Train and evaluate each model on each data file\n",
    "results = {}\n",
    "for data_file in data_files:\n",
    "    # Extract sequence length and overlap from file name\n",
    "    parts = data_file.split('_')\n",
    "    seq_len = int(parts[4])\n",
    "    overlap = int(parts[-1].split('.')[0])\n",
    "        \n",
    "    # Load data\n",
    "    data = torch.load(os.path.join('sequences', data_file))\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    \n",
    "    # Split data into training, validation, and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    batch_size = 16\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Update the models dictionary\n",
    "    input_dim = seq_len * 8  # Assuming your input shape is (batch_size, seq_len, 8)\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(input_dim),\n",
    "        'MLP': MLP(input_dim),\n",
    "        'LSTM': LSTMModel(input_size=8, hidden_size=128, num_layers=1),\n",
    "        'Bidirectional LSTM': BidirectionalLSTMModel(input_size=8, hidden_size=128, num_layers=1),\n",
    "    }\n",
    "    \n",
    "    train_description = f\"seqlen{seq_len}overlap{overlap}\"\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name} on {data_file}\")\n",
    "        start_time = time.time()\n",
    "        train(model, train_loader, val_loader, epochs=70, patience=5, model_class=type(model), description=train_description)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nEvaluating {name} on {data_file}\")\n",
    "        accuracy = evaluate(model, test_loader)\n",
    "        \n",
    "        results[f\"{name} on {data_file}\"] = {'accuracy': accuracy, 'train_time': train_time}\n",
    "\n",
    "# Print summary of results\n",
    "print(\"\\nSummary of Results:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}: Accuracy = {result['accuracy']:.4f}, Training Time = {result['train_time']:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
